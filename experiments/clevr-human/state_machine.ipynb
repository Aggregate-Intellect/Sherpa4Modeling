{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-27 09:50:48.501\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msherpa_ai.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m127\u001b[0m - \u001b[33m\u001b[1mConfig: Slack environment variables not set\u001b[0m\n",
      "\u001b[32m2024-11-27 09:50:48.502\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msherpa_ai.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mConfig: OpenAI environment variables are set\u001b[0m\n",
      "\u001b[32m2024-11-27 09:50:48.502\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msherpa_ai.config\u001b[0m:\u001b[36mcheck_vectordb_setting\u001b[0m:\u001b[36m113\u001b[0m - \u001b[33m\u001b[1mConfig: No vector database environment variables are set. Using in-memory Chroma database. This may not be what you intended.\u001b[0m\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\chenp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sherpa_ai.memory import Belief\n",
    "from states import get_actions, add_state_machine\n",
    "from utils import load_processed_dataset\n",
    "import random\n",
    "from langchain_openai import ChatOpenAI\n",
    "from sherpa_ai.agents.qa_agent import QAAgent\n",
    "from sherpa_ai.events import Event, EventType\n",
    "from policy import ReactPolicy\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Dogdays/clevr_subset\", token=True)[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-4o-mini\"\n",
    "llm = ChatOpenAI(model=model_name, temperature=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next: Run the react state machine with Clevr example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_MACHINE = \"\"\"\n",
    "Start --> Filtering: start\n",
    "Filtering --> Filtering: filter_with_attribute\n",
    "Filtering --> Querying: continue\n",
    "Filtering --> Finish: answer\n",
    "Querying --> Relating: continue\n",
    "Querying --> Querying: query_attribute\n",
    "Querying --> Finish: answer\n",
    "Relating --> Checking: continue\n",
    "Relating --> Relating: get_related_objects\n",
    "Relating --> Finish: answer\n",
    "Checking --> Filtering: continue\n",
    "Checking --> Checking: get_same_objects\n",
    "Checking --> Finish: answer\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "State Machine\n",
      "---\n",
      "stateDiagram-v2\n",
      "  direction LR\n",
      "  classDef s_default fill:white,color:black\n",
      "  classDef s_inactive fill:white,color:black\n",
      "  classDef s_parallel color:black,fill:white\n",
      "  classDef s_active color:red,fill:darksalmon\n",
      "  classDef s_previous color:blue,fill:azure\n",
      "  \n",
      "  state \"Start\" as Start\n",
      "  Class Start s_active\n",
      "  state \"Exploring\" as Exploring\n",
      "  Class Exploring s_default\n",
      "  state Exploring {\n",
      "    [*] --> Exploring_Filtering\n",
      "    state \"Filtering\" as Exploring_Filtering\n",
      "    state \"Checking\" as Exploring_Checking\n",
      "    state \"Relating\" as Exploring_Relating\n",
      "    state \"Querying\" as Exploring_Querying\n",
      "  }\n",
      "  state \"Finish\" as Finish\n",
      "  Class Finish s_default\n",
      "  \n",
      "  Start --> Exploring: start\n",
      "  Exploring_Filtering --> Exploring_Filtering: filter_with_attribute\n",
      "  Exploring_Filtering --> Exploring_Relating: other_options\n",
      "  Exploring_Relating --> Exploring_Checking: other_options\n",
      "  Exploring_Relating --> Exploring_Relating: get_related_objects\n",
      "  Exploring_Checking --> Exploring_Filtering: other_options\n",
      "  Exploring_Checking --> Exploring_Checking: get_same_objects\n",
      "  Exploring --> Exploring: query_attribute\n",
      "  Exploring --> Finish: answer\n",
      "  [*] --> Start\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sherpa_ai.memory.belief.Belief at 0x256a9c1e340>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_state_machine(belief, action_map,  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9298df9130ee45e9998a3ab11ba78e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chenp\\anaconda3\\envs\\sherpa\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "AGENT_DESCRIPTION = \"\"\"\n",
    "You are a question answering assistant helping users to find answers to their questions based on a specific scene.\n",
    "Each object in the scene contain the following properties: color, size, shape, material, and a unique identifier.\n",
    "The properties are from a fixed set of values:\n",
    "– Size: One of large or small.\n",
    "– Color: One of gray, red, blue, green, brown, purple, cyan, or yellow.\n",
    "– Shape: One of cube (block), sphere, or cylinder.\n",
    "– Material: One of rubber (matte) or metal (shinning).\n",
    "- Unique identifier: The index of the object in the scene, starting from 0.\n",
    "\n",
    "{scene}\n",
    "\n",
    "Objects in the scene also have the following relationships: left, right, front or behind.\n",
    "\n",
    "Given the question, first identify ALL relevant objects in the scene using filter. Then identify their relations.\n",
    "\n",
    "If answering the question requires and object that does not exist in the scene, give answer \"no\" if it is a boolean question, or \"0\" if it is count question.\n",
    "\n",
    "When provide action arguments, ONLY use the values from the fixed set of values above.\n",
    "\"\"\"\n",
    "# Scene: {scene}\n",
    "idx = 0\n",
    "use_scene = True\n",
    "\n",
    "for sample in tqdm(dataset.select(range(100))):\n",
    "    scene = sample[\"scene\"]\n",
    "    test_question = sample[\"question\"]\n",
    "\n",
    "\n",
    "    belief = Belief()\n",
    "    action_map = get_actions(belief, llm)\n",
    "    add_state_machine(belief, action_map, print_sm=False)\n",
    "    \n",
    "    belief.set(\"scene\", scene)\n",
    "\n",
    "    if use_scene:\n",
    "        belief.set(\"agent_scene\", scene)\n",
    "        agent_description = AGENT_DESCRIPTION.format(scene=f\"Scene: {scene}\")\n",
    "    else:\n",
    "        agent_description = AGENT_DESCRIPTION.format(scene=\"\")\n",
    "\n",
    "    policy = ReactPolicy(\n",
    "        role_description=agent_description,\n",
    "        llm=llm,\n",
    "    )\n",
    "\n",
    "    agent = QAAgent(\n",
    "        llm=llm,\n",
    "        belief=belief,\n",
    "        description=agent_description,\n",
    "        num_runs=10,\n",
    "        policy=policy,\n",
    "    )\n",
    "\n",
    "    belief.set_current_task(\n",
    "        Event(\n",
    "            EventType.task, \"user\", f\"{test_question}.\"\n",
    "        )\n",
    "    )\n",
    "    agent.run()\n",
    "\n",
    "    if belief.state_machine.state != \"Finish\":\n",
    "        belief.state_machine.answer()\n",
    "\n",
    "    result = [str(event) for event in belief.internal_events]\n",
    "\n",
    "    answer = belief.get(\n",
    "        \"answer_count_action\",\n",
    "        belief.get(\n",
    "            \"answer_judging_action\",\n",
    "            belief.get(\n",
    "                \"answer_querying_action\",\n",
    "                belief.get(\"answer_action\", \"No answer found.\"),\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    results.append((result, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_answers = [question[\"answer\"] for question in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 85 0.85\n"
     ]
    }
   ],
   "source": [
    "correct = [1 if str(p[1][\"answer\"]) == str(a) else 0 for p, a in zip(results, real_answers)]\n",
    "print(len(correct), sum(correct), sum(correct) / len(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"predicted\": [r[1][\"answer\"] for r in results],\n",
    "    \"reasoning\": [r[0] for r in results],\n",
    "    \"actual\": real_answers\n",
    "})\n",
    "\n",
    "df.to_csv(f\"state_machine_results_{model_name}_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'split': 'val',\n",
       " 'image_filename': 'CLEVR_val_007515.png',\n",
       " 'answer': 'cylinder',\n",
       " 'question': 'What shape do three large objects have in common?',\n",
       " 'image_index': 7515}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[83]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = []\n",
    "for log, question in results:\n",
    "    results_dict.append({\n",
    "        \"log\": log,\n",
    "        \"question\": question\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results_dict)\n",
    "df.to_csv(\"results_sm_gpt-4o.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objects': [{'color': 'purple',\n",
       "   'size': 'large',\n",
       "   'shape': 'cylinder',\n",
       "   'material': 'metal'},\n",
       "  {'color': 'green',\n",
       "   'size': 'large',\n",
       "   'shape': 'cylinder',\n",
       "   'material': 'rubber'},\n",
       "  {'color': 'gray', 'size': 'large', 'shape': 'cube', 'material': 'metal'},\n",
       "  {'color': 'brown',\n",
       "   'size': 'small',\n",
       "   'shape': 'cylinder',\n",
       "   'material': 'rubber'},\n",
       "  {'color': 'green',\n",
       "   'size': 'small',\n",
       "   'shape': 'cylinder',\n",
       "   'material': 'metal'}],\n",
       " 'relationships': {'right': [[], [0, 4], [0, 1, 4], [0, 1, 2, 4], [0]],\n",
       "  'behind': [[], [0, 2, 3], [0], [0, 2], [0, 1, 2, 3]],\n",
       "  'front': [[1, 2, 3, 4], [4], [1, 3, 4], [1, 4], []],\n",
       "  'left': [[1, 2, 3, 4], [2, 3], [3], [], [1, 2, 3]]}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenes[2210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there an equal number of shiny and matte objects?\n"
     ]
    }
   ],
   "source": [
    "print(test_question['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'split': 'val',\n",
       " 'image_filename': 'CLEVR_val_007329.png',\n",
       " 'answer': 'yes',\n",
       " 'question': 'Are there an equal number of shiny and matte objects?',\n",
       " 'image_index': 7329}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sherpa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
