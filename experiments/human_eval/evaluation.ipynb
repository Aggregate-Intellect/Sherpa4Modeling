{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from human_eval.evaluation import evaluate_functional_correctness\n",
    "from human_eval.data import HUMAN_EVAL\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_correctness(\n",
    "    sample_file: str,\n",
    "    k: str = \"1,10,100\",\n",
    "    n_workers: int = 4,\n",
    "    timeout: float = 3.0,\n",
    "    problem_file: str = HUMAN_EVAL,\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluates the functional correctness of generated samples, and writes\n",
    "    results to f\"{sample_file}_results.jsonl.gz\"\n",
    "    \"\"\"\n",
    "    k = list(map(int, k.split(\",\")))\n",
    "    results = evaluate_functional_correctness(sample_file, k, n_workers, timeout, problem_file)\n",
    "    return results\n",
    "\n",
    "def get_average_llm_calls(sample_file: str):\n",
    "    results = []\n",
    "    with open(sample_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            results.append(json.loads(line))\n",
    "    \n",
    "    if \"num_llm_calls\" not in results[0]:\n",
    "        if \"direct\" in sample_file:\n",
    "            return 1\n",
    "        return -1\n",
    "    \n",
    "    num_calls = [r[\"num_llm_calls\"] for r in results]\n",
    "\n",
    "    return np.mean(num_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"results\"\n",
    "\n",
    "llms = [\"gpt-4o\", \"gpt-4o-mini\", \"Qwen2.5-7B-Instruct-Turbo\", \"Qwen2.5-72B-Instruct-Turbo\", \"Qwen2.5-Coder-32B-Instruct\"] # , \"Meta-Llama-3.1-8B-Instruct-Turbo\", \"Meta-Llama-3.1-70B-Instruct-Turbo\"\n",
    "approaches = [\"direct_prompt\", \"agent_coder\", \"agent_coder_improved\", \"state_machine\"]\n",
    "llm_names = [\"GPT-4o\", \"GPT-4o Mini\",  \"Qwen 2.5 7B\", \"Qwen 2.5 72B\", \"Qwen 2.5 Coder 32B\"] # \"Llama 3.1 8B\", \"Llama 3.1 70B\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating gpt-4o direct_prompt\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:00, 4826.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:02<00:00, 66.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to results/gpt-4o/direct_prompt.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 5837.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating gpt-4o agent_coder\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:00, 4648.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:04<00:00, 39.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to results/gpt-4o/agent_coder.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 6048.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating gpt-4o agent_coder_improved\n",
      "Evaluating gpt-4o state_machine\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:00, 3451.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:02<00:00, 70.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to results/gpt-4o/state_machine.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 6871.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating gpt-4o-mini direct_prompt\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:00, 3017.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:06<00:00, 27.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to results/gpt-4o-mini/direct_prompt.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 7385.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating gpt-4o-mini agent_coder\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:00, 3973.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 164/164 [00:04<00:00, 40.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to results/gpt-4o-mini/agent_coder.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 8982.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating gpt-4o-mini agent_coder_improved\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:00, 3377.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:04<00:00, 38.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to results/gpt-4o-mini/agent_coder_improved.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 6663.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating gpt-4o-mini state_machine\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:00, 4237.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:05<00:00, 27.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to results/gpt-4o-mini/state_machine.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 7780.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Qwen2.5-7B-Instruct-Turbo direct_prompt\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:00, 4318.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:02<00:00, 58.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to results/Qwen2.5-7B-Instruct-Turbo/direct_prompt.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 7251.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Qwen2.5-7B-Instruct-Turbo agent_coder\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:00, 4409.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:04<00:00, 34.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to results/Qwen2.5-7B-Instruct-Turbo/agent_coder.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 2083.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Qwen2.5-7B-Instruct-Turbo agent_coder_improved\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:00, 1132.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:05<00:00, 28.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to results/Qwen2.5-7B-Instruct-Turbo/agent_coder_improved.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 4610.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Qwen2.5-7B-Instruct-Turbo state_machine\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:00, 3726.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:03<00:00, 46.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to results/Qwen2.5-7B-Instruct-Turbo/state_machine.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 7769.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Qwen2.5-72B-Instruct-Turbo direct_prompt\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:00, 2862.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:02<00:00, 61.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to results/Qwen2.5-72B-Instruct-Turbo/direct_prompt.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 6400.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Qwen2.5-72B-Instruct-Turbo agent_coder\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:00, 3172.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:02<00:00, 69.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to results/Qwen2.5-72B-Instruct-Turbo/agent_coder.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 4239.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Qwen2.5-72B-Instruct-Turbo agent_coder_improved\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:00, 3587.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:03<00:00, 51.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to results/Qwen2.5-72B-Instruct-Turbo/agent_coder_improved.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 7048.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Qwen2.5-72B-Instruct-Turbo state_machine\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:00, 3601.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:03<00:00, 44.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to results/Qwen2.5-72B-Instruct-Turbo/state_machine.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 6482.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Qwen2.5-Coder-32B-Instruct direct_prompt\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:00, 2830.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:02<00:00, 59.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to results/Qwen2.5-Coder-32B-Instruct/direct_prompt.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 5868.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Qwen2.5-Coder-32B-Instruct agent_coder\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:00, 3476.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:06<00:00, 27.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to results/Qwen2.5-Coder-32B-Instruct/agent_coder.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 2034.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Qwen2.5-Coder-32B-Instruct agent_coder_improved\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:00, 3497.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:04<00:00, 34.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to results/Qwen2.5-Coder-32B-Instruct/agent_coder_improved.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 6053.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Qwen2.5-Coder-32B-Instruct state_machine\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:00, 3809.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:02<00:00, 62.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to results/Qwen2.5-Coder-32B-Instruct/state_machine.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 7172.59it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = []\n",
    "for i, llm in enumerate(llms):\n",
    "    for approach in approaches:\n",
    "        print(f\"Evaluating {llm} {approach}\")\n",
    "        result = {\n",
    "            \"llm\": llm_names[i],\n",
    "            \"approach\": approach,\n",
    "            \"average_llm_calls\": -1,\n",
    "            \"pass@1\": -1\n",
    "        }\n",
    "\n",
    "        filename = f\"{folder}/{llm}/{approach}.jsonl\"\n",
    "        if os.path.exists(filename):\n",
    "            result[\"average_llm_calls\"] = get_average_llm_calls(filename)\n",
    "            result[\"pass@1\"] = evaluate_correctness(filename)[\"pass@1\"]\n",
    "        evaluation_results.append(result)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llm</th>\n",
       "      <th>approach</th>\n",
       "      <th>average_llm_calls</th>\n",
       "      <th>pass@1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>direct_prompt</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>agent_coder</td>\n",
       "      <td>8.292683</td>\n",
       "      <td>0.914634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>agent_coder_improved</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>state_machine</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.896341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPT-4o Mini</td>\n",
       "      <td>direct_prompt</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.841463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GPT-4o Mini</td>\n",
       "      <td>agent_coder</td>\n",
       "      <td>8.878049</td>\n",
       "      <td>0.896341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GPT-4o Mini</td>\n",
       "      <td>agent_coder_improved</td>\n",
       "      <td>6.670732</td>\n",
       "      <td>0.884146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GPT-4o Mini</td>\n",
       "      <td>state_machine</td>\n",
       "      <td>3.695122</td>\n",
       "      <td>0.871951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Qwen 2.5 7B</td>\n",
       "      <td>direct_prompt</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.823171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Qwen 2.5 7B</td>\n",
       "      <td>agent_coder</td>\n",
       "      <td>9.024390</td>\n",
       "      <td>0.835366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Qwen 2.5 7B</td>\n",
       "      <td>agent_coder_improved</td>\n",
       "      <td>6.304878</td>\n",
       "      <td>0.884146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Qwen 2.5 7B</td>\n",
       "      <td>state_machine</td>\n",
       "      <td>3.884146</td>\n",
       "      <td>0.847561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Qwen 2.5 72B</td>\n",
       "      <td>direct_prompt</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Qwen 2.5 72B</td>\n",
       "      <td>agent_coder</td>\n",
       "      <td>8.439024</td>\n",
       "      <td>0.896341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Qwen 2.5 72B</td>\n",
       "      <td>agent_coder_improved</td>\n",
       "      <td>6.207317</td>\n",
       "      <td>0.884146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Qwen 2.5 72B</td>\n",
       "      <td>state_machine</td>\n",
       "      <td>3.329268</td>\n",
       "      <td>0.890244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Qwen 2.5 Coder 32B</td>\n",
       "      <td>direct_prompt</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Qwen 2.5 Coder 32B</td>\n",
       "      <td>agent_coder</td>\n",
       "      <td>8.792683</td>\n",
       "      <td>0.902439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Qwen 2.5 Coder 32B</td>\n",
       "      <td>agent_coder_improved</td>\n",
       "      <td>5.829268</td>\n",
       "      <td>0.920732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Qwen 2.5 Coder 32B</td>\n",
       "      <td>state_machine</td>\n",
       "      <td>3.134146</td>\n",
       "      <td>0.914634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   llm              approach  average_llm_calls    pass@1\n",
       "0               GPT-4o         direct_prompt           1.000000  0.908537\n",
       "1               GPT-4o           agent_coder           8.292683  0.914634\n",
       "2               GPT-4o  agent_coder_improved          -1.000000 -1.000000\n",
       "3               GPT-4o         state_machine           3.000000  0.896341\n",
       "4          GPT-4o Mini         direct_prompt           1.000000  0.841463\n",
       "5          GPT-4o Mini           agent_coder           8.878049  0.896341\n",
       "6          GPT-4o Mini  agent_coder_improved           6.670732  0.884146\n",
       "7          GPT-4o Mini         state_machine           3.695122  0.871951\n",
       "8          Qwen 2.5 7B         direct_prompt           1.000000  0.823171\n",
       "9          Qwen 2.5 7B           agent_coder           9.024390  0.835366\n",
       "10         Qwen 2.5 7B  agent_coder_improved           6.304878  0.884146\n",
       "11         Qwen 2.5 7B         state_machine           3.884146  0.847561\n",
       "12        Qwen 2.5 72B         direct_prompt           1.000000  0.847561\n",
       "13        Qwen 2.5 72B           agent_coder           8.439024  0.896341\n",
       "14        Qwen 2.5 72B  agent_coder_improved           6.207317  0.884146\n",
       "15        Qwen 2.5 72B         state_machine           3.329268  0.890244\n",
       "16  Qwen 2.5 Coder 32B         direct_prompt           1.000000  0.896341\n",
       "17  Qwen 2.5 Coder 32B           agent_coder           8.792683  0.902439\n",
       "18  Qwen 2.5 Coder 32B  agent_coder_improved           5.829268  0.920732\n",
       "19  Qwen 2.5 Coder 32B         state_machine           3.134146  0.914634"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
